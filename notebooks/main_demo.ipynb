{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f27944ae",
            "metadata": {},
            "source": [
                "# Pr√°ctica Final: Asistente Tur√≠stico de Tenerife (RAG)\n",
                "\n",
                "Notebook de desarrollo paso a paso.\n",
                "\n",
                "## 1. Configuraci√≥n Inicial\n",
                "Verificaci√≥n de que el entorno y las claves API est√°n correctamente cargadas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "8951c85e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Directorio Ra√≠z: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\n",
                        "‚úÖ API Key de OpenAI cargada correctamente.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# 1. Configuramos el path para poder importar m√≥dulos de src/\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "# 2. Cargamos variables de entorno\n",
                "load_dotenv(os.path.join(project_root, '.env'))\n",
                "\n",
                "# 3. Verificaci√≥n\n",
                "print(f\"Directorio Ra√≠z: {project_root}\")\n",
                "\n",
                "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
                "if api_key and api_key.startswith(\"sk-\"):\n",
                "    print(\"‚úÖ API Key de OpenAI cargada correctamente.\")\n",
                "else:\n",
                "    print(\"‚ùå ERROR: No se detect√≥ la API Key o el formato es incorrecto.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "id": "test_api_connection",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚è≥ Probando conexi√≥n con OpenAI...\n",
                        "‚úÖ Respuesta del LLM: Conexi√≥n exitosa. ¬øEn qu√© puedo ayudarte hoy?\n"
                    ]
                }
            ],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "print(\"‚è≥ Probando conexi√≥n con OpenAI...\")\n",
                "try:\n",
                "    # Instanciamos el modelo b√°sico\n",
                "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
                "    response = llm.invoke(\"Di 'Conexi√≥n exitosa' si me lees.\")\n",
                "    print(f\"‚úÖ Respuesta del LLM: {response.content}\")\n",
                "except Exception as e:\n",
                "    print(f\"‚ùå Error de conexi√≥n con OpenAI: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ingesta_header",
            "metadata": {},
            "source": [
                "## 2. Ingesta de Datos (Lectura PDF)\n",
                "Cargaremos la gu√≠a tur√≠stica desde la carpeta `data/raw` y procesaremos su contenido."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "id": "load_pdf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üìÑ Buscando PDF en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\data\\raw\\TENERIFE.pdf\n",
                        "‚úÖ PDF Cargado con √©xito. Total p√°ginas: 25\n",
                        "\n",
                        "--- Muestra de contenido (P√°g 10) ---\n",
                        "o La Playa de Los Patos \n",
                        "o Playa del Anc√≥n \n",
                        " \n",
                        "Nota: Para llegar estas playas hay que caminar un rato y algunas son de dif√≠cil acceso \n",
                        "(la de Los Patos). Tambi√©n hay que ir a estas playas cuando la marea est√© baja, si no...\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "\n",
                "# Ruta al archivo PDF (Ahora en data/raw)\n",
                "pdf_path = os.path.join(project_root, \"data\", \"raw\", \"TENERIFE.pdf\")\n",
                "\n",
                "print(f\"üìÑ Buscando PDF en: {pdf_path}\")\n",
                "\n",
                "if os.path.exists(pdf_path):\n",
                "    loader = PyPDFLoader(pdf_path)\n",
                "    docs = loader.load()\n",
                "    print(f\"‚úÖ PDF Cargado con √©xito. Total p√°ginas: {len(docs)}\")\n",
                "    \n",
                "    # Verificamos contenido de una p√°gina al azar (p√°g 10, √≠ndice 9)\n",
                "    print(\"\\n--- Muestra de contenido (P√°g 10) ---\")\n",
                "    print(docs[9].page_content[:500] + \"...\")\n",
                "else:\n",
                "    print(\"‚ùå ERROR: El archivo PDF no existe en la ruta especificada.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "id": "split_text",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "‚úÖ Documento dividido en 30 fragmentos (chunks).\n",
                        "Tama√±o promedio del chunk: 570 caracteres.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "# Dividimos el texto en fragmentos (chunks) para que entren en el contexto del LLM\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=1000,    # Caracteres por chunk\n",
                "    chunk_overlap=200,  # Solapamiento para no perder contexto entre cortes\n",
                "    length_function=len,\n",
                "    add_start_index=True,\n",
                ")\n",
                "\n",
                "chunks = text_splitter.split_documents(docs)\n",
                "print(f\"‚úÖ Documento dividido en {len(chunks)} fragmentos (chunks).\")\n",
                "print(f\"Tama√±o promedio del chunk: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} caracteres.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "refactor_check",
            "metadata": {},
            "source": [
                "## 3. Validaci√≥n del M√≥dulo `src.data.loader`\n",
                "Ahora verificamos que el c√≥digo refactorizado en `src/` funciona igual que el c√≥digo experimental de arriba."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "id": "use_loader_class",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîÑ Probando clase DataLoader refactorizada...\n",
                        "üìÑ Cargando PDF desde: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\data\\raw\\TENERIFE.pdf\n",
                        "‚úÖ PDF cargado con 25 p√°ginas.\n",
                        "‚úÇÔ∏è  Dividiendo 25 documentos en chunks...\n",
                        "‚úÖ Se generaron 30 fragmentos.\n",
                        "\n",
                        "‚úÖ Validaci√≥n completada: 30 chunks generados mediante la clase encapsulada.\n"
                    ]
                }
            ],
            "source": [
                "from src.data.loader import DataLoader\n",
                "\n",
                "print(\"üîÑ Probando clase DataLoader refactorizada...\")\n",
                "# Inicializamos el loader con la misma ruta\n",
                "loader = DataLoader(pdf_path)\n",
                "\n",
                "# Documentos\n",
                "docs_refactored = loader.load()\n",
                "\n",
                "# Chunks\n",
                "chunks_refactored = loader.split(docs_refactored)\n",
                "\n",
                "print(f\"\\n‚úÖ Validaci√≥n completada: {len(chunks_refactored)} chunks generados mediante la clase encapsulada.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vector_store_header",
            "metadata": {},
            "source": [
                "## 4. Motor Vectorial (Embeddings)\n",
                "Convertiremos los chunks de texto en vectores num√©ricos y los almacenaremos en ChromaDB."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "id": "create_vector_store",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "embedding... (Esto puede tardar un poco)\n",
                        "‚úÖ Base de datos vectorial creada en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\chroma_db\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.vectorstores import Chroma\n",
                "from langchain_openai import OpenAIEmbeddings\n",
                "import shutil\n",
                "\n",
                "# Ruta donde guardaremos la base de datos vectorial\n",
                "chroma_path = os.path.join(project_root, \"chroma_db\")\n",
                "\n",
                "# Limpiamos la BD anterior si existe para empezar de cero\n",
                "if os.path.exists(chroma_path):\n",
                "    print(\"üßπ Limpiando base de datos vectorial existente...\")\n",
                "    shutil.rmtree(chroma_path)\n",
                "\n",
                "print(\"embedding... (Esto puede tardar un poco)\")\n",
                "\n",
                "# Inicializamos Embeddings y VectorStore\n",
                "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
                "vector_store = Chroma.from_documents(\n",
                "    documents=chunks_refactored,\n",
                "    embedding=embeddings,\n",
                "    persist_directory=chroma_path\n",
                ")\n",
                "\n",
                "print(f\"‚úÖ Base de datos vectorial creada en: {chroma_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 16,
            "id": "test_search",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "üîç Buscando: '¬øQu√© altura tiene el Teide?'\n",
                        "\n",
                        "--- Resultado 1 ---\n",
                        "Si quer√©is subir hasta el pico del Teide, pod√©is hacerlo desde aqu√≠ haciendo uso de \n",
                        "los telef√©ricos del Teide. Y, si quer√©is m√°s info sobre el Teide, pod√©is ir al Centro de \n",
                        "Visitantes de El Portillo que es gratis. \n",
                        "Si os apetece, pod√©is subir de noche cuando est√© despejado, ya que desde El Teide \n",
                        "...\n",
                        "\n",
                        "--- Resultado 2 ---\n",
                        "‚Ä¢ El Teide \n",
                        "Si vais a Tenerife y no sub√≠s al Parque Nacional del Teide, simplemente no hab√©is \n",
                        "estado en Tenerife. \n",
                        " \n",
                        "Mi recomendaci√≥n ‚Äì esto es simplemente gustos personales m√≠os ‚Äì para subir al \n",
                        "Teide es subir por la carretera TF24 (carretera de La Esperanza) desde la rotonda de \n",
                        "Padre Anchieta en...\n",
                        "\n",
                        "--- Resultado 3 ---\n",
                        "del Teide pertenece a La Orotava. \n",
                        "o En las fiestas de La Orotava (consideradas Fiestas de Inter√©s Tur√≠stico \n",
                        "Nacional) se hace una alfombra gigante de arenas y tierras procedentes del \n",
                        "Teide y tiene el r√©cord Guinness de mayor tapiz de tierra del mundo. \n",
                        "A La Orotava pertenecen tres playas de las q...\n"
                    ]
                }
            ],
            "source": [
                "# Prueba de b√∫squeda sem√°ntica\n",
                "query = \"¬øQu√© altura tiene el Teide?\"\n",
                "print(f\"üîç Buscando: '{query}'\")\n",
                "\n",
                "results = vector_store.similarity_search(query, k=3)\n",
                "\n",
                "for i, res in enumerate(results):\n",
                "    print(f\"\\n--- Resultado {i+1} ---\")\n",
                "    print(res.page_content[:300] + \"...\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
