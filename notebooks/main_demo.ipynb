{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "f27944ae",
            "metadata": {},
            "source": [
                "# PrÃ¡ctica Final: Asistente TurÃ­stico de Tenerife (RAG)\n",
                "\n",
                "Notebook de desarrollo paso a paso.\n",
                "\n",
                "## 1. ConfiguraciÃ³n Inicial\n",
                "VerificaciÃ³n de que el entorno y las claves API estÃ¡n correctamente cargadas."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "id": "8951c85e",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Directorio RaÃ­z: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\n",
                        "âœ… API Key de OpenAI cargada correctamente.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import sys\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "# 1. Configuramos el path para poder importar mÃ³dulos de src/\n",
                "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "# 2. Cargamos variables de entorno\n",
                "load_dotenv(os.path.join(project_root, '.env'))\n",
                "\n",
                "# 3. VerificaciÃ³n\n",
                "print(f\"Directorio RaÃ­z: {project_root}\")\n",
                "\n",
                "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
                "if api_key and api_key.startswith(\"sk-\"):\n",
                "    print(\"âœ… API Key de OpenAI cargada correctamente.\")\n",
                "else:\n",
                "    print(\"âŒ ERROR: No se detectÃ³ la API Key o el formato es incorrecto.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "id": "test_api_connection",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "â³ Probando conexiÃ³n con OpenAI...\n",
                        "âœ… Respuesta del LLM: ConexiÃ³n exitosa. Â¿En quÃ© puedo ayudarte hoy?\n"
                    ]
                }
            ],
            "source": [
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "print(\"â³ Probando conexiÃ³n con OpenAI...\")\n",
                "try:\n",
                "    # Instanciamos el modelo bÃ¡sico\n",
                "    llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
                "    response = llm.invoke(\"Di 'ConexiÃ³n exitosa' si me lees.\")\n",
                "    print(f\"âœ… Respuesta del LLM: {response.content}\")\n",
                "except Exception as e:\n",
                "    print(f\"âŒ Error de conexiÃ³n con OpenAI: {e}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ingesta_header",
            "metadata": {},
            "source": [
                "## 2. Ingesta de Datos (Lectura PDF)\n",
                "Cargaremos la guÃ­a turÃ­stica desde la carpeta `data/raw` y procesaremos su contenido."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "id": "load_pdf",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ“„ Buscando PDF en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\data\\raw\\TENERIFE.pdf\n",
                        "âœ… PDF Cargado con Ã©xito. Total pÃ¡ginas: 25\n",
                        "\n",
                        "--- Muestra de contenido (PÃ¡g 10) ---\n",
                        "o La Playa de Los Patos \n",
                        "o Playa del AncÃ³n \n",
                        " \n",
                        "Nota: Para llegar estas playas hay que caminar un rato y algunas son de difÃ­cil acceso \n",
                        "(la de Los Patos). TambiÃ©n hay que ir a estas playas cuando la marea estÃ© baja, si no...\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.document_loaders import PyPDFLoader\n",
                "\n",
                "# Ruta al archivo PDF (Ahora en data/raw)\n",
                "pdf_path = os.path.join(project_root, \"data\", \"raw\", \"TENERIFE.pdf\")\n",
                "\n",
                "print(f\"ðŸ“„ Buscando PDF en: {pdf_path}\")\n",
                "\n",
                "if os.path.exists(pdf_path):\n",
                "    loader = PyPDFLoader(pdf_path)\n",
                "    docs = loader.load()\n",
                "    print(f\"âœ… PDF Cargado con Ã©xito. Total pÃ¡ginas: {len(docs)}\")\n",
                "    \n",
                "    # Verificamos contenido de una pÃ¡gina al azar (pÃ¡g 10, Ã­ndice 9)\n",
                "    print(\"\\n--- Muestra de contenido (PÃ¡g 10) ---\")\n",
                "    print(docs[9].page_content[:500] + \"...\")\n",
                "else:\n",
                "    print(\"âŒ ERROR: El archivo PDF no existe en la ruta especificada.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "id": "split_text",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Documento dividido en 30 fragmentos (chunks).\n",
                        "TamaÃ±o promedio del chunk: 570 caracteres.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
                "\n",
                "# Dividimos el texto en fragmentos (chunks) para que entren en el contexto del LLM\n",
                "text_splitter = RecursiveCharacterTextSplitter(\n",
                "    chunk_size=1000,    # Caracteres por chunk\n",
                "    chunk_overlap=200,  # Solapamiento para no perder contexto entre cortes\n",
                "    length_function=len,\n",
                "    add_start_index=True,\n",
                ")\n",
                "\n",
                "chunks = text_splitter.split_documents(docs)\n",
                "print(f\"âœ… Documento dividido en {len(chunks)} fragmentos (chunks).\")\n",
                "print(f\"TamaÃ±o promedio del chunk: {sum(len(c.page_content) for c in chunks) / len(chunks):.0f} caracteres.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "refactor_check",
            "metadata": {},
            "source": [
                "## 3. ValidaciÃ³n del MÃ³dulo `src.data.loader`\n",
                "Ahora verificamos que el cÃ³digo refactorizado en `src/` funciona igual que el cÃ³digo experimental de arriba."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "id": "use_loader_class",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Probando clase DataLoader refactorizada...\n",
                        "ðŸ“„ Cargando PDF desde: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\data\\raw\\TENERIFE.pdf\n",
                        "âœ… PDF cargado con 25 pÃ¡ginas.\n",
                        "âœ‚ï¸  Dividiendo 25 documentos en chunks...\n",
                        "âœ… Se generaron 30 fragmentos.\n",
                        "\n",
                        "âœ… ValidaciÃ³n completada: 30 chunks generados mediante la clase encapsulada.\n"
                    ]
                }
            ],
            "source": [
                "from src.data.loader import DataLoader\n",
                "\n",
                "print(\"ðŸ”„ Probando clase DataLoader refactorizada...\")\n",
                "# Inicializamos el loader con la misma ruta\n",
                "loader = DataLoader(pdf_path)\n",
                "\n",
                "# Documentos\n",
                "docs_refactored = loader.load()\n",
                "\n",
                "# Chunks\n",
                "chunks_refactored = loader.split(docs_refactored)\n",
                "\n",
                "print(f\"\\nâœ… ValidaciÃ³n completada: {len(chunks_refactored)} chunks generados mediante la clase encapsulada.\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vector_store_header",
            "metadata": {},
            "source": [
                "## 4. Motor Vectorial (Embeddings)\n",
                "Convertiremos los chunks de texto en vectores numÃ©ricos y los almacenaremos en ChromaDB."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "id": "create_vector_store",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ§¹ Limpiando base de datos vectorial existente...\n",
                        "ðŸ§  Generando embeddings... (Esto puede tardar un poco)\n",
                        "âœ… Base de datos vectorial creada en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\chroma_db\n"
                    ]
                }
            ],
            "source": [
                "from langchain_community.vectorstores import Chroma\n",
                "from langchain_openai import OpenAIEmbeddings\n",
                "import shutil\n",
                "\n",
                "# Ruta donde guardaremos la base de datos vectorial\n",
                "chroma_path = os.path.join(project_root, \"chroma_db\")\n",
                "\n",
                "# Limpiamos la BD anterior si existe para empezar de cero\n",
                "if os.path.exists(chroma_path):\n",
                "    print(\"ðŸ§¹ Limpiando base de datos vectorial existente...\")\n",
                "    shutil.rmtree(chroma_path)\n",
                "\n",
                "print(\"ðŸ§  Generando embeddings... (Esto puede tardar un poco)\")\n",
                "\n",
                "# Inicializamos Embeddings y VectorStore\n",
                "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
                "vector_store = Chroma.from_documents(\n",
                "    documents=chunks_refactored,\n",
                "    embedding=embeddings,\n",
                "    persist_directory=chroma_path\n",
                ")\n",
                "\n",
                "print(f\"âœ… Base de datos vectorial creada en: {chroma_path}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "id": "test_search",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ” Buscando: 'Â¿QuÃ© altura tiene el Teide?'\n",
                        "\n",
                        "--- Resultado 1 ---\n",
                        "Si querÃ©is subir hasta el pico del Teide, podÃ©is hacerlo desde aquÃ­ haciendo uso de \n",
                        "los telefÃ©ricos del Teide. Y, si querÃ©is mÃ¡s info sobre el Teide, podÃ©is ir al Centro de \n",
                        "Visitantes de El Portillo que es gratis. \n",
                        "Si os apetece, podÃ©is subir de noche cuando estÃ© despejado, ya que desde El Teide \n",
                        "...\n",
                        "\n",
                        "--- Resultado 2 ---\n",
                        "â€¢ El Teide \n",
                        "Si vais a Tenerife y no subÃ­s al Parque Nacional del Teide, simplemente no habÃ©is \n",
                        "estado en Tenerife. \n",
                        " \n",
                        "Mi recomendaciÃ³n â€“ esto es simplemente gustos personales mÃ­os â€“ para subir al \n",
                        "Teide es subir por la carretera TF24 (carretera de La Esperanza) desde la rotonda de \n",
                        "Padre Anchieta en...\n",
                        "\n",
                        "--- Resultado 3 ---\n",
                        "del Teide pertenece a La Orotava. \n",
                        "o En las fiestas de La Orotava (consideradas Fiestas de InterÃ©s TurÃ­stico \n",
                        "Nacional) se hace una alfombra gigante de arenas y tierras procedentes del \n",
                        "Teide y tiene el rÃ©cord Guinness de mayor tapiz de tierra del mundo. \n",
                        "A La Orotava pertenecen tres playas de las q...\n"
                    ]
                }
            ],
            "source": [
                "# Prueba de bÃºsqueda semÃ¡ntica\n",
                "query = \"Â¿QuÃ© altura tiene el Teide?\"\n",
                "print(f\"ðŸ” Buscando: '{query}'\")\n",
                "\n",
                "results = vector_store.similarity_search(query, k=3)\n",
                "\n",
                "for i, res in enumerate(results):\n",
                "    print(f\"\\n--- Resultado {i+1} ---\")\n",
                "    print(res.page_content[:300] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "vector_store_refactor_check",
            "metadata": {},
            "source": [
                "## 5. ValidaciÃ³n del MÃ³dulo `src.data.vector_store`\n",
                "Verificamos que la clase `VectorStoreManager` gestiona correctamente la creaciÃ³n y bÃºsqueda."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "id": "use_vector_manager",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ”„ Probando VectorStoreManager refactorizada...\n",
                        "ðŸ§¹ Eliminando base de datos antigua en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\chroma_db_refactored\n",
                        "ðŸ§  Generando embeddings y almacenando en ChromaDB...\n",
                        "âœ… Base de datos vectorial lista en: f:\\development\\Development\\Master IA\\LLM-large-language-models-entrega-final\\chroma_db_refactored\n",
                        "ðŸ” Buscando: 'Â¿DÃ³nde se encuentra el auditorio AdÃ¡n MartÃ­n?'\n",
                        "\n",
                        "--- [Refactor] Resultado 1 ---\n",
                        "o Auditorio de Tenerife [vÃ­deo - ubicaciÃ³n] \n",
                        " \n",
                        " \n",
                        "o Plaza de EspaÃ±a [vÃ­deo - ubicaciÃ³n]...\n",
                        "\n",
                        "--- [Refactor] Resultado 2 ---\n",
                        "o Callejear direcciÃ³n Plaza del Adelantado [ubicaciÃ³n] y tomar algo por ahÃ­ si \n",
                        "hace buen tiempo (si querÃ©is comer, os recomiendo La Cueva de Casiano - \n",
                        "ubicaciÃ³n â€“ y pedir la batata con almogrote y, de resto, que os recomienden \n",
                        "ellos mismos). \n",
                        " \n",
                        "Los sitios de interÃ©s comentados son los siguientes:...\n",
                        "\n",
                        "--- [Refactor] Resultado 3 ---\n",
                        "o Al ir hacia Buenavista, aparcar cerca de la Plaza de los Remedios y ver un \n",
                        "poco la zona, sin mÃ¡s. RecomendaciÃ³n tomarse un dulcito en la pastelerÃ­a El \n",
                        "Aderno....\n"
                    ]
                }
            ],
            "source": [
                "from src.data.vector_store import VectorStoreManager\n",
                "\n",
                "print(\"ðŸ”„ Probando VectorStoreManager refactorizada...\")\n",
                "\n",
                "chroma_path_ref = os.path.join(project_root, \"chroma_db_refactored\")\n",
                "\n",
                "manager = VectorStoreManager(persist_directory=chroma_path_ref)\n",
                "\n",
                "# Crear DB\n",
                "manager.create_vector_store(chunks_refactored, reset=True)\n",
                "\n",
                "# Buscar\n",
                "results_ref = manager.search(\"Â¿DÃ³nde se encuentra el auditorio AdÃ¡n MartÃ­n?\")\n",
                "\n",
                "for i, res in enumerate(results_ref):\n",
                "    print(f\"\\n--- [Refactor] Resultado {i+1} ---\")\n",
                "    print(res.page_content[:300] + \"...\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "rag_logic_header",
            "metadata": {},
            "source": [
                "## 6. LÃ³gica RAG (Retrieval Augmented Generation)\n",
                "Implementamos la cadena completa: Pregunta -> BÃºsqueda de Contexto -> Prompt con Contexto -> Respuesta LLM."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "id": "rag_setup",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "âœ… Cadena RAG construida exitosamente.\n"
                    ]
                }
            ],
            "source": [
                "from langchain_core.prompts import ChatPromptTemplate\n",
                "from langchain_core.runnables import RunnablePassthrough\n",
                "from langchain_core.output_parsers import StrOutputParser\n",
                "\n",
                "# 1. Definimos el Prompt del Asistente\n",
                "template = \"\"\"\n",
                "Eres un guÃ­a turÃ­stico experto en Tenerife, amigable y conocedor.\n",
                "Usa la siguiente informaciÃ³n de contexto para responder a la pregunta del turista.\n",
                "Si no encuentras la respuesta en el contexto, di amablemente que no tienes esa informaciÃ³n, no inventes nada.\n",
                "\n",
                "Contexto:\n",
                "{context}\n",
                "\n",
                "Pregunta del Turista: {question}\n",
                "\n",
                "Respuesta:\n",
                "\"\"\"\n",
                "prompt = ChatPromptTemplate.from_template(template)\n",
                "\n",
                "# 2. Obtenemos el Retriever (Buscador) de nuestra clase VectorStoreManager\n",
                "# Usaremos 'manager' que validamos en el paso anterior y que ya tiene los datos cargados\n",
                "retriever = manager.get_retriever(k=4)\n",
                "\n",
                "# 3. Definimos la Cadena RAG (Chain)\n",
                "def format_docs(docs):\n",
                "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
                "\n",
                "rag_chain = (\n",
                "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
                "    | prompt\n",
                "    | llm  # Usamos el 'llm' que instanciamos al pricipio (ChatOpenAI)\n",
                "    | StrOutputParser()\n",
                ")\n",
                "\n",
                "print(\"âœ… Cadena RAG construida exitosamente.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "id": "rag_test",
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "ðŸ‘¤ Pregunta: Â¿QuÃ© planes culturales recomiendas en Santa Cruz?\n",
                        "\n",
                        "ðŸ¤– Generando respuesta...\n",
                        "\n",
                        "ðŸ’¬ Respuesta del Asistente:\n",
                        "En Santa Cruz de Tenerife, te recomendarÃ­a visitar el Auditorio de Tenerife, que es un impresionante edificio de arquitectura moderna y uno de los sÃ­mbolos de la ciudad. TambiÃ©n puedes dar un paseo por la Plaza de EspaÃ±a y disfrutar de la arquitectura colonial de la zona. Otra opciÃ³n es visitar el Parque GarcÃ­a Sanabria, un hermoso parque con esculturas y jardines. AdemÃ¡s, puedes explorar el centro de la ciudad y descubrir sus tiendas, restaurantes y galerÃ­as de arte. Â¡Espero que disfrutes de tu visita cultural en Santa Cruz!\n"
                    ]
                }
            ],
            "source": [
                "# Prueba Real\n",
                "pregunta = \"Â¿QuÃ© planes culturales recomiendas en Santa Cruz?\"\n",
                "\n",
                "print(f\"ðŸ‘¤ Pregunta: {pregunta}\\n\")\n",
                "print(\"ðŸ¤– Generando respuesta...\\n\")\n",
                "\n",
                "respuesta = rag_chain.invoke(pregunta)\n",
                "\n",
                "print(\"ðŸ’¬ Respuesta del Asistente:\")\n",
                "print(respuesta)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.4"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
